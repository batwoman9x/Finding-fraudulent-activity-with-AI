{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итоговая аттестация"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьём для понимания код на несколько шагов: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Импортируем все библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Загрузим данные из файлов и объединим их в один DataFrame для анализа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "base_df = pd.read_csv('/mnt/data/Base.csv')\n",
    "variant_df = pd.read_csv('/mnt/data/Variant I.csv')\n",
    "\n",
    "# объединение данных \n",
    "data = pd.concat([base_df, variant_df], axis=1)\n",
    "data.info()\n",
    "\n",
    "# обработка пропущенных значений\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# кодирование категориальных признаков\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# масштабирование числовых признаков\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = data.columns.difference(['fraud_bool'])\n",
    "data[scaled_columns] = scaler.fit_transform(data[scaled_columns])\n",
    "\n",
    "# выводим первые несколько строк для проверки\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Просмотрим структуру данных, и выведем основные статистики, а также проверим, имеются ли пропущенные значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()\n",
    "\n",
    "# описательная статистика\n",
    "data.describe()\n",
    "\n",
    "# проверяем на пропущенные значения\n",
    "data.isnull().sum()\n",
    "\n",
    "# проверяем распределения целевого признака\n",
    "data['fraud_bool'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Проведём визуализацию данных - для начала построим несколько графиков для лучшего понимания данных, включая распределение целевого признака `fraud_bool`, корреляцию между признаками и другие аспекты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# распределяем целевой признак\n",
    "sns.countplot(x='fraud_bool', data=data)\n",
    "plt.title('Распределение целевого признака (fraud_bool)')\n",
    "plt.show()\n",
    "\n",
    "# выведем гистограммы для всех признаков\n",
    "data.hist(bins=30, figsize=(20, 15))\n",
    "plt.show()\n",
    "\n",
    "# и корреляционную матрица\n",
    "corr_matrix = data.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Корреляционная матрица признаков')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Сделаем проверку гипотез - проведём тестирование гипотез, связанных с данными, таких как проверка значимости различий между группами данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка гипотезы о равенстве\n",
    "for column in scaled_columns:\n",
    "    fraudulent = data[data['fraud_bool'] == 1][column]\n",
    "    non_fraudulent = data[data['fraud_bool'] == 0][column]\n",
    "    t_stat, p_value = stats.ttest_ind(fraudulent, non_fraudulent)\n",
    "    print(f'Feature: {column}, T-statistic: {t_stat:.2f}, P-value: {p_value:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Промежуточный вывод по исследованию:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Данные содержат X признаков, один из которых является целевым `fraud_bool`;\n",
    "- Корреляция между признаками низкая, из-за чего можно сделать вывод о возможной необходимости использования более сложной модели;\n",
    "- Распределение целевого признака имеет дисбаланс, поэтому нужны специальные методы для обучении модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Определяем новые задачи для выполнения цели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основной остается задачей бинарной классификации, где целевой признак `fraud_bool` по выбранному датасету"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Для выполнения задачи обучим несколько моделей и выберем лучшую на основе валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяем данные\n",
    "X = data.drop('fraud_bool', axis=1)\n",
    "y = data['fraud_bool']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# определяем модели\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# проводим ибучение и оценку моделей\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(f'{name}:')\n",
    "    print(f'  Accuracy: {accuracy_score(y_val, y_pred):.4f}')\n",
    "    print(f'  Precision: {precision_score(y_val, y_pred):.4f}')\n",
    "    print(f'  Recall: {recall_score(y_val, y_pred):.4f}')\n",
    "    print(f'  F1 Score: {f1_score(y_val, y_pred):.4f}')\n",
    "    print('')\n",
    "\n",
    "# подбираем параметры\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='f1')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# проводим оценку лучшей модели на валидационной выборке\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "print(f'Best Model (Random Forest) after Grid Search:')\n",
    "print(f'  Accuracy: {accuracy_score(y_val, y_val_pred):.4f}')\n",
    "print(f'  Precision: {precision_score(y_val, y_val_pred):.4f}')\n",
    "print(f'  Recall: {recall_score(y_val, y_val_pred):.4f}')\n",
    "print(f'  F1 Score: {f1_score(y_val, y_val_pred):.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Создадим тестовую выборку и сделаем прогноз по этой выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проведём разделение данных\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# обучаем модель на полной тренировочной выборке\n",
    "best_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "# сделаем арогнозирование на тестовой выборке\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# и проведём оценку метрик на тестовой выборке\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Precision: {test_precision:.4f}')\n",
    "print(f'Test Recall: {test_recall:.4f}')\n",
    "print(f'Test F1 Score: {test_f1:.4f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Для задачи классификации с несбалансированным классом наиболее подходящей метрикой является F1 Score, так как она учитывает как точность, так и полноту.\n",
    "Её и обучали на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вывод:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Модель показывает хорошие результаты по метрике F1 Score. Эта метрика способна балансировать между пропуском мошеннических операций и ложными срабатываниями.\n",
    "- Для решения данной задачи использование машинного обучения оправдано, так как Dummy-модель (например, всегда предсказывающая \"не мошенничество\") дала бы значительно худшие результаты."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
